{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "**Sophia and Victoria**\n",
    "In Ferguson Missouri the Summer 2014, an unarmed black teenager was shot 6 times and subsequently died from his wounds. The white officer was bot indicted by a grand jury 3 months later. \n",
    "\n",
    "The initial incident and the following decision incited both a physical firestorm as the streets of Ferguson were filled with fires and protests, and virtually through social media as people from around the world weighed in. \n",
    "\n",
    "This project explores the phenomenon of social media activism, news sharing, and the relationship between the virtual and physical world through analysis of 13 million tweets over the two weeks following the shooting, and 15 million tweets about the indictment decision in the two weeks following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing everthing!\n",
    "Let's get ready to do some cool data things!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in Data\n",
    "Here, we're using a function that we've developed to read in the data, a certain number of lines at a time. This uses a file of cleaned tweets that can be found..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ReadToDf(linesAtATime,filepath, max=-1):\n",
    "    start = time.time()\n",
    "    df = pd.DataFrame()\n",
    "    i = 0\n",
    "    data = [] \n",
    "    \n",
    "    #Open and read in the file\n",
    "    with open(filepath) as cleanedTweets:\n",
    "        for tweet in cleanedTweets:\n",
    "            i += 1\n",
    "            jsonline = json.loads(tweet)\n",
    "            data.append(jsonline)\n",
    "            #aggregate once we've read in the appropriate number of liens\n",
    "            if (i % linesAtATime == 0):\n",
    "                print \"number of tweets parsed: \", i\n",
    "                print \"total time elapsed: \", time.time() - start\n",
    "                df = df.append(pd.DataFrame(data=data))\n",
    "                #reset the data\n",
    "                data = []\n",
    "        #Handle the last few tweets\n",
    "            if (max > 0 and i >= max):\n",
    "                break\n",
    "        df = pd.DataFrame(data=data).append(df)\n",
    "    #return the aggregation\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = ReadToDf(100000, 'data/cleanedShootingTweets.json',max=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "This is where we're going to clean data that we've read in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['createdDatetime'] =  pd.to_datetime(\n",
    "    df['created_at'], \n",
    "    format = '%a %b %d %H:%M:%S +0000 %Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Tweets over Time - Victoria\n",
    "Let's first get a handle of the data that we have. In the dataset related to the shooting, we have approximately 13 million tweets worth of data. Over the course of the first week, statements from police, from the family of Michael Brown, statements from the police officer Darren Wilson, and unrest from the streets were recorded and shared wildly across the web. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Raw numbers of tweets over time\n",
    "users = df.set_index('createdDatetime').groupby([pd.TimeGrouper('Min')]).count().reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "users.plot(kind='line', x='createdDatetime', y='created_at', ax=ax)\n",
    "plt.title('Number of Tweets by Users')\n",
    "\n",
    "ax.set_ylabel('Count of tweets')\n",
    "ax.set_xlabel('Date/Time')\n",
    "\n",
    "#Overlaying Special Events\n",
    "#August 11, 10AM - first police department demonstration\n",
    "#August 11, 4PM - parents ask for stop to violence\n",
    "#August 11, 8PM - tear gas used at protest\n",
    "#August 12, 10AM - protest in St. Louis\n",
    "#August 12, 12PM - Al Sharpton addresses crowds\n",
    "#August 12, 4PM - Obama makes a statement\n",
    "#August 13, 6PM - Reporters detained\n",
    "#August 13, 9PM - Tear gas used again, and at reporters\n",
    "#August 14, 7AM - Antonio French released from jail\n",
    "#August 14, 11:40AM - Obama Address\n",
    "#August 14, 6PM - Silent Vigils, first peaceful night\n",
    "#August 15, 8:45AM - Darren Wilson names\n",
    "#August 15, 12:30PM - Assassination statement by family\n",
    "#August 15 Evening - Huge amounts of protest\n",
    "#August 16, 3PM - State of emergency issued, curfew issued\n",
    "#August 17 - Afternoon - Federal Autopsy Ordered\n",
    "#August 18 - 2AM - Federal Gaurd Ordered into town\n",
    "#August 18 - 3:30PM - third Obama address\n",
    "#August 18 - Trayvon Martin's mother published letter\n",
    "#August 19 - 7AM - family on the Today Show\n",
    "#August 19 - 1PM - another man is shot\n",
    "#August 22 - 12PM - national gaurd ordered to withdraw\n",
    "#August 23 - Online fundraisers for officer surpass that of Brown\n",
    "#August 23 - 7PM - Obama address\n",
    "#August 24 - 12PM - Private Viewing, Requests for no Violence\n",
    "#August 25 - Funeral\n",
    "\n",
    "calendar_dates = {'FirstDemo':datetime(2014,8,11,10,0,0),\n",
    "                 'ParentReq':datetime(2014,8,11,16,0,0),\n",
    "                 'TearGas':datetime(2014,8,11,20,0,0),\n",
    "                 'StLouisProtest':datetime(2014,8,12,10,0,0),\n",
    "                 'AlSharpton':datetime(2014,8,12,12,0,0),\n",
    "                 'Obama':datetime(2014,8,12,16,0,0),\n",
    "                 'Reporters':datetime(2014,8,13,18,0,0),\n",
    "                 'TearGas2':datetime(2014,8,13,21,0,0),\n",
    "                 'AntonioFrench':datetime(2014,8,14,7,0,0),\n",
    "                 'Obama2':datetime(2014,8,14,11,40,0),\n",
    "                 'SilentVigils':datetime(2014,8,14,18,0,0),\n",
    "                 'DarrenWilson':datetime(2014,8,15,8,45,0),\n",
    "                 'CharacterAssassination':datetime(2014,8,15,12,30,0),\n",
    "                 'StateOfEmergency':datetime(2014,8,16,15,0,0),\n",
    "                 'FederalGaurd':datetime(2014,8,18,2,0,0),\n",
    "                 'Obama3':datetime(2014,8,18,15,30,0),\n",
    "                 'TodayShow':datetime(2014,8,19,7,0,0),\n",
    "                 'AnotherShot':datetime(2014,8,19,13,0,0),\n",
    "                 'GaurdWithdrawn':datetime(2014,8,22,12,0,0),\n",
    "                 'Obama4':datetime(2014,8,23,19,0,0),\n",
    "                 'Viewing':datetime(2014,8,24,12,0,0)}\n",
    "\n",
    "for event in calendar_dates:\n",
    "    plt.axvline(x=calendar_dates.get(event),ymin=0, ymax=4000, linewidth=4,color='g',label=event)\n",
    "#     plt.text(calendar_dates.get(event),600,event)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, a certain percentage of users have place or geoencoding available on their tweets. Spatially we can see how tweets were generated following the shooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "from ipywidgets import widgets\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#let's grab the coordinates from the coordinates field, which is actually a dictionary\n",
    "coords = []\n",
    "for i in range(len(df)):\n",
    "    location = df['coordinates'][i]\n",
    "    try: #want to make sure that null values don't throw an exception\n",
    "        coords.append(location.get('coordinates'))\n",
    "    except:\n",
    "        coords.append([None,None])\n",
    "\n",
    "df['Coords'] = coords\n",
    "df['x'] = df['Coords'].apply(lambda x: x[0])\n",
    "df['y'] = df['Coords'].apply(lambda x: x[1])\n",
    "\n",
    "#now, let's grab the information from place, which is similarly a very detailed dictionary of elements\n",
    "coordinates = []\n",
    "for i in range(len(df)):\n",
    "    location = df['place'][i]\n",
    "    try:\n",
    "        coordinates.append(location.get('bounding_box').get('coordinates'))\n",
    "    except:\n",
    "        coordinates.append([[[0,0],[0,0],[0,0],[0,0]]])\n",
    "\n",
    "mean_coords = []\n",
    "for box in coordinates:\n",
    "    mean_coord_x = (box[0][0][0]+box[0][1][0]+box[0][2][0]+box[0][3][0])/4\n",
    "    mean_coord_y = (box[0][0][1]+box[0][1][1]+box[0][2][1]+box[0][3][1])/4\n",
    "    mean_coords.append([mean_coord_x,mean_coord_y])\n",
    "\n",
    "df['P_Coords'] = mean_coords\n",
    "df['x_p'] = df['P_Coords'].apply(lambda x: x[0])\n",
    "df['y_p'] = df['P_Coords'].apply(lambda x: x[1])\n",
    "\n",
    "df['createdDatetime_day'] = df['createdDatetime'].apply(lambda x: int(x.day))\n",
    "df['createdDatetime_hour'] = df['createdDatetime'].apply(lambda x: int(x.hour))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['x'].fillna(value = df['x_p'], inplace = True)\n",
    "df['y'].fillna(value = df['y_p'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latLonPopulated = df[(df['x'] != 0) & (df['y'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "from tempfile import NamedTemporaryFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotAnimationProperly(list_functions, data_to_plot, colors_to_plot):\n",
    "    for i in range(len(list_functions)):\n",
    "        list_functions[i].set_data(data_to_plot[i].x,data_to_plot[i].y)\n",
    "        list_functions[i].set_color(colors_to_plot[i])\n",
    "\n",
    "#Note, the animation code courtesy of and adapted from http://jakevdp.github.io/blog/2013/05/12/embedding-matplotlib-animations/\n",
    "VIDEO_TAG = \"\"\"<video controls>\n",
    " <source src=\"data:video/x-m4v;base64,{0}\" type=\"video/mp4\">\n",
    " Your browser does not support the video tag.\n",
    "</video>\"\"\"\n",
    "\n",
    "def anim_to_html(anim):\n",
    "    if not hasattr(anim, '_encoded_video'):\n",
    "        with NamedTemporaryFile(suffix='.mp4') as f:\n",
    "            anim.save(f.name, fps=20, extra_args=['-vcodec', 'libx264', '-pix_fmt', 'yuv420p'])\n",
    "            video = open(f.name, \"rb\").read()\n",
    "        anim._encoded_video = video.encode(\"base64\")\n",
    "    \n",
    "    return VIDEO_TAG.format(anim._encoded_video)\n",
    "\n",
    "def display_animation(anim):\n",
    "    plt.close(anim._fig)\n",
    "    return HTML(anim_to_html(anim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(xlim=(-180, 180), ylim=(-75, 75))\n",
    "# plt.axis([-180, 180, -75, 75])\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "scat, = plt.plot([], [],'o')\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    scat.set_data([], [])\n",
    "    return scat,\n",
    "\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(i):\n",
    "    day = round(i/24) + 17\n",
    "    hour = i - (day-17)*24\n",
    "    subset = []\n",
    "    subset = latLonPopulated[\n",
    "        (latLonPopulated['createdDatetime_day'] == day) & \n",
    "        (latLonPopulated['createdDatetime_hour'] ==hour)]\n",
    "\n",
    "    scat.set_data(subset.x,subset.y)\n",
    "    \n",
    "    return scat,\n",
    "\n",
    "animation.Animation._repr_html_ = anim_to_html\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, frames=48, interval=5000, blit=False)\n",
    "\n",
    "# call our new function to display the animation\n",
    "display_animation(anim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And over all time, statically, this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the cartopy map, going simple outline for now\n",
    "plt.figure(figsize=(15,15))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "#straight-up coordinate data which we just finished recoding\n",
    "plt.scatter(latLonPopulated.x,latLonPopulated.y,color='r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#as a hexbin instead\n",
    "#the cartopy map, going simple outline for now\n",
    "plt.figure(figsize=(15,15))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "#straight-up coordinate data which we just finished recoding\n",
    "plt.hexbin(latLonPopulated.x,latLonPopulated.y,cmap=cm.jet)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags - Sophia\n",
    "Now, let's explore the different hashtags used by users. First, let's create a dataframe that has one row per tweet-hashtag combination. So, a tweet using two hashtags would translate into a dataframe with two rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create this dataframe by looping over the rows in the dataframe, and looping over the hashtags in each tweet. For each tweet, we will create a json object that represents the row that should be added to our new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtagRows = []\n",
    "hashtagMap = {'MICHAELBROWN': 'MIKEBROWN'}\n",
    "for i,tweet in df.iterrows():\n",
    "    for hashtag in tweet['entities_hashtags_text']:\n",
    "        \n",
    "        mappedhashtag = hashtag.upper()\n",
    "        if (mappedhashtag in hashtagMap):\n",
    "            mappedhashtag = hashtagMap[mappedhashtag]\n",
    "        #Do we want to map michael brown to mike brown and similar stuff?\n",
    "        hashtagRows.append({\n",
    "                'createdDatetime': tweet['createdDatetime'],\n",
    "                'hashtag': mappedhashtag,\n",
    "                'tweetId': tweet['id_str']\n",
    "            })\n",
    "print \"creating dataframe\"\n",
    "hashtagsDf = pd.DataFrame(hashtagRows)\n",
    "hashtagsDf['x'] = df['x']\n",
    "hashtagsDf['y'] = df['y']\n",
    "hashtagsDf['createdDatetime_day'] = df['createdDatetime_day']\n",
    "hashtagsDf['createdDatetime_hour'] = df['createdDatetime_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtagsDf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataframe, let's get the most popular tweets! We will do this by grouping the dataframe by hashtag and then aggregating by count. We'll sort by count, and then transform that information to a list that we can use later. Right now, we'll start by getting the top 10 hashtags and plotting those over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numTopHashtags = 10\n",
    "popularHashtagsList = (hashtagsDf\n",
    "                   .groupby('hashtag')\n",
    "                   .count()\n",
    "                   .reset_index()\n",
    "                   .sort_values(by='createdDatetime', ascending=False)['hashtag']\n",
    "                   .tolist())[0:numTopHashtags]\n",
    "\n",
    "print(popularHashtagsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the most popular hashtags, let's filter the hashtags dataframe for just those hashtags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popularHashtagsDf = hashtagsDf[hashtagsDf.hashtag.isin(popularHashtagsList)]\n",
    "popularHashtagsDf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's count the number of times each hashtag was used in a given minute. To do this, we will group the dataframe by datetime.minute and hashtag and then aggregate by count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtagTimeCounts = (popularHashtagsDf\n",
    "                     .set_index('createdDatetime')\n",
    "                     .groupby([pd.TimeGrouper('H'), 'hashtag'])\n",
    "                     .count()\n",
    "                     .reset_index())\n",
    "hashtagTimeCounts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've gotten the counts for a particular hashtag every minute, let's plot this over time as a line graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for hashtag in popularHashtagsList:\n",
    "    filteredHashtagTimeCounts = hashtagTimeCounts[hashtagTimeCounts.hashtag == hashtag]\n",
    "    filteredHashtagTimeCounts.plot(kind = 'line', x = 'createdDatetime', y = 'tweetId', label = hashtag, ax = ax)\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Number of Tweets over Time')\n",
    "plt.title('Hashtag useage over Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see the number of times each hashtag was used in a tweet in this dataset. Unfortunately, it appears that the hashtag \"Ferguson\" was used much more than any of the other hashtags, so this plot is a little hard to read. To adjust for that, let's \"normalize\" each hashtag line on this graph. To do this, we will divide the number of times that hashtag was used in any given minute by the maxiumum times that hashtag was used in any minute. This will mean that we can see all the lines on the same set of axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for hashtag in popularHashtagsList:\n",
    "    filteredHashtagTimeCounts = hashtagTimeCounts[hashtagTimeCounts.hashtag == hashtag]\n",
    "    maxCount = filteredHashtagTimeCounts['tweetId'].max()\n",
    "    filteredHashtagTimeCounts['normalizedCounts'] = filteredHashtagTimeCounts['tweetId']/maxCount\n",
    "    filteredHashtagTimeCounts.plot(kind = 'line', x = 'createdDatetime', y = 'normalizedCounts', label = hashtag, ax = ax)\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Number of Tweets over Time')\n",
    "plt.title('Hashtag useage over Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most popular hashtags seem to follow a similar trajectory. First of all, let's spend a little bit of time talking about what each hashtag means.\n",
    "\n",
    "**Ferguson:**\n",
    "This hashtag appears to be refering in a boader context to the events that occured in Ferguson. [source](http://www.dailydot.com/politics/ferguson-michael-brown-eric-garner-black-lives-matter-hashtag-activism/)\n",
    "\n",
    "**Mike/Michael Brown:**\n",
    "This hashtag, somewhat self-explanatorily, refers to Michael Brown, the unarmed teen that was shot by police. [source](http://www.dailydot.com/politics/ferguson-michael-brown-eric-garner-black-lives-matter-hashtag-activism/)\n",
    "\n",
    "**TCOT:**\n",
    "This hashtag stands for \"Top Conservatives on Twitter\" and is used to bring together conservatives on twitter. The corresponding liberal hashtag is \"P2\". [source](http://blog.sfgate.com/ybenjamin/2010/07/27/the-secret-twitter-war-for-americas-independents-tcot-vs-p2/)  Very quickly, after the events in Ferguson, there started to be political discussions about Ferguson. \n",
    "\n",
    "**Hands Up Don't Shoot:**\n",
    "\"Hands up Don't Shoot\" was a phrase commonly used in the Ferguson protests. This phrase references witness' statements that say that Michael Brown had his hands up before he was shot by police. This phrase was adopted in peaceful protest after the Ferguson shooting [source](http://www.cbc.ca/newsblogs/yourcommunity/2014/08/hands-up-dont-shoot-gesture-spreads-online-in-support-of-ferguson-protesters.html)\n",
    "\n",
    "**STL:**\n",
    "This hashtag, similarly to the hashtag \"Ferguson\" is in reference o the city of Saint Louis, Missouri.  [source](https://tagdef.com/stl)\n",
    "\n",
    "**Unite Blue:**\n",
    "Although this hashtag is typically used to refer to \"uniting liberals on twitter\" [source](), in this context this hashtag refers to people uniting in support of the police force. [source]()\n",
    "\n",
    "**Ezell Ford: **\n",
    "Ezell Ford is another African American man that was also killed after being shot by police. He was shot on August 11th, 2014 in LA. [source](https://en.wikipedia.org/wiki/Shooting_of_Ezell_Ford)\n",
    "\n",
    "**Ferguson Shooting:**\n",
    "This hashtag, appears to be used to just refer to events surrounding the Ferguson shooting. [source]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TALK ABOUT THE GRAPH HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even see where these hashtags are most popular!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print hashtagsDf.info()\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(xlim=(-180, 180), ylim=(-75, 75))\n",
    "# plt.axis([-180, 180, -75, 75])\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "scat, = plt.plot([], [],'o')\n",
    "scat_top_1, = plt.plot([], [],'o')\n",
    "scat_top_2, = plt.plot([], [],'o')\n",
    "scat_top_3, = plt.plot([], [],'o')\n",
    "scat_top_4, = plt.plot([], [],'o')\n",
    "scat_top_5, = plt.plot([], [],'o')\n",
    "scat_top_6, = plt.plot([], [],'o')\n",
    "scat_top_7, = plt.plot([], [],'o')\n",
    "scat_top_8, = plt.plot([], [],'o')\n",
    "scat_top_9, = plt.plot([], [],'o')\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    scat.set_data([], [])\n",
    "    scat_top_1.set_data([],[])\n",
    "    return scat,scat_top_1,scat_top_2,scat_top_3,scat_top_4,scat_top_5,scat_top_6,scat_top_7,scat_top_8,scat_top_9,\n",
    "\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(i):\n",
    "    day = round(i/24) + 17\n",
    "    hour = i - (day-17)*24\n",
    "    subset = []\n",
    "    color = []\n",
    "    label = []\n",
    "    for j,hashtag in enumerate(popularHashtagsList):\n",
    "        subset.append(latLonPopulated[\n",
    "            (hashtagsDf['createdDatetime_day'] == day) & \n",
    "            (hashtagsDf['createdDatetime_hour']==hour) & \n",
    "            (hashtagsDf['hashtag'] == hashtag)])\n",
    "        color.append(cm.jet(j/float(len(popularHashtagsList))))\n",
    "\n",
    "    plotAnimationProperly([scat,scat_top_1,scat_top_2,scat_top_3,scat_top_4,scat_top_5,scat_top_6,scat_top_7,scat_top_8,scat_top_9],subset,color)\n",
    "    \n",
    "    return scat,scat_top_1,scat_top_2,scat_top_3,scat_top_4,scat_top_5,scat_top_6,scat_top_7,scat_top_8,scat_top_9,\n",
    "\n",
    "animation.Animation._repr_html_ = anim_to_html\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, frames=48, interval=5000, blit=False)\n",
    "\n",
    "# call our new function to display the animation\n",
    "display_animation(anim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users\n",
    "introduction goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verified Users - Sophia\n",
    "Additionally, one of the things we wanted to investigate was the role that verified users play in raising awareness about a certain event. On twitter verified users are users that represent an organization (like a news source) or a public figure. We hypotheize that getting more verified users involved in talking about social justice will cause more non-verified users to also be engaged in the conversation, as they see what verififed users are saying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verified = df[df.user_verified == True]\n",
    "normal = df[df.user_verified == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the number of tweets by verified users every minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groupedVerified = verified.set_index('createdDatetime').groupby([pd.TimeGrouper('Min')]).count().reset_index()\n",
    "groupedNormal = normal.set_index('createdDatetime').groupby([pd.TimeGrouper('Min')]).count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot this information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "\n",
    "groupedVerified.plot(kind='line', x='createdDatetime', y='created_at', label='Verified Users', ax=ax)\n",
    "groupedNormal.plot(kind='line', x='createdDatetime', y='created_at', ax = ax, secondary_y=True, label='Non-verified Users')\n",
    "plt.title('Number of tweets by Users')\n",
    "\n",
    "ax.set_ylabel('Count of twets (Verified users)', color='b')\n",
    "ax.right_ax.set_ylabel('Count of tweets (Non-Verified users)', color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see whether or not the number of non-verified users' tweets and number of verified tweets there are are related, let's correlate the number of tweets by verified users and the number of tweets by non-verified users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verifiedtweetsCount = groupedVerified.sort_values(by='createdDatetime')['created_at'].tolist()\n",
    "normaltweetsCount = groupedNormal.sort_values(by='createdDatetime')['created_at'].tolist()\n",
    "\n",
    "corr = np.correlate(verifiedtweetsCount, normaltweetsCount, mode='full')\n",
    "delays = range(-len(corr)/2, len(corr)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(delays,corr)\n",
    "plt.xlabel('delay in number of hours')\n",
    "plt.ylabel('correlation')\n",
    "plt.title('Correlation between number of verified tweets and number of non-verified account tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's also get the index (in hours) for the highest autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delays[np.argmax(corr)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the correlation of those two vectors finds that they are most correlated when the verifiedTweetsCount and the normalTweets count are offset by 402. This means that about 6.7 hours after an increase in ____ there tends to also be an increase in ___."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweets - Victoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unpack(data):\n",
    "    try:\n",
    "        res = data[0]\n",
    "    except:\n",
    "        res = 'None'\n",
    "    return res\n",
    "df['unpacked_entities'] = df['entities_user_mentions_screen_name'].apply(unpack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO MAKE DATEFRAME FOR NODES\n",
    "# df.info()\n",
    "df.sort_values(by='retweet_count')\n",
    "plt.figure(figsize=(15,15))\n",
    "# G=nx.from_pandas_dataframe(df[0:10000:], source='user_id_str',target='unpacked_entities')\n",
    "\n",
    "G=nx.Graph()\n",
    "\n",
    "#set layout\n",
    "\n",
    "\n",
    "#add nodes\n",
    "G.add_nodes_from(df.user_screen_name[0:1000:])\n",
    "G.nodes()\n",
    "\n",
    "#create tuples for edges\n",
    "subset = df[['user_screen_name','unpacked_entities']][0:1000:]\n",
    "tuples = [tuple(x) for x in subset.values]\n",
    "\n",
    "#add edges\n",
    "G.add_edges_from(tuples)\n",
    "G.number_of_edges()\n",
    "\n",
    "#draw graph\n",
    "G.remove_node('None')\n",
    "# df['x_int'] = df['x'].apply(lambda x: int(x))\n",
    "# df['y_int'] = df['y'].apply(lambda x: int(x))\n",
    "# G.pos=(df['x_int'],df['y_int'])\n",
    "nx.draw_networkx(G,alpha=0.1,cmap=cm.jet,font_size=0)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions - Victoria and Sophia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
