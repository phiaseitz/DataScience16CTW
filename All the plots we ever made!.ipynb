{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "**Sophia and Victoria**\n",
    "\n",
    "In Ferguson Missouri the Summer 2014, an unarmed black teenager was shot 6 times and subsequently died from his wounds. The white officer was bot indicted by a grand jury 3 months later. \n",
    "\n",
    "The initial incident and the following decision incited both a physical firestorm as the streets of Ferguson were filled with fires and protests, and virtually through social media as people from around the world weighed in. \n",
    "\n",
    "This project explores the phenomenon of social media activism, news sharing, and the relationship between the virtual and physical world through analysis of 13 million tweets over the two weeks following the shooting, and 15 million tweets about the indictment decision in the two weeks following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing everthing!\n",
    "Let's get ready to do some cool data things!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Sophia/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from ipywidgets import widgets\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in Data\n",
    "Here, we're using a function that we've developed to read in the data, a certain number of lines at a time. This uses a file of cleaned tweets that can be found..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ReadToDf(linesAtATime,filepath, max=-1):\n",
    "    start = time.time()\n",
    "    df = pd.DataFrame()\n",
    "    i = 0\n",
    "    data = [] \n",
    "    \n",
    "    #Open and read in the file\n",
    "    with open(filepath) as cleanedTweets:\n",
    "        for tweet in cleanedTweets:\n",
    "            i += 1\n",
    "            jsonline = json.loads(tweet)\n",
    "            data.append(jsonline)\n",
    "            #aggregate once we've read in the appropriate number of liens\n",
    "            if (i % linesAtATime == 0):\n",
    "                print \"number of tweets parsed: \", i\n",
    "                print \"total time elapsed: \", time.time() - start\n",
    "                df = df.append(pd.DataFrame(data=data))\n",
    "                #reset the data\n",
    "                data = []\n",
    "        #Allow us to handle the last few tweets, and to truncate the data if we just want to run unit tests\n",
    "            if (max > 0 and i >= max):\n",
    "                break\n",
    "        df = pd.DataFrame(data=data).append(df)\n",
    "    #return the aggregation\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tweets parsed:  500000\n",
      "total time elapsed:  9.01916599274\n",
      "number of tweets parsed:  1000000\n",
      "total time elapsed:  20.4038479328\n",
      "number of tweets parsed:  1500000\n",
      "total time elapsed:  32.8145618439\n",
      "number of tweets parsed:  2000000\n",
      "total time elapsed:  46.7838070393\n",
      "number of tweets parsed:  2500000\n",
      "total time elapsed:  60.3250980377\n",
      "number of tweets parsed:  3000000\n",
      "total time elapsed:  76.4616868496\n",
      "number of tweets parsed:  3500000\n",
      "total time elapsed:  92.7481968403\n",
      "number of tweets parsed:  4000000\n",
      "total time elapsed:  110.749866009\n",
      "number of tweets parsed:  4500000\n",
      "total time elapsed:  126.559936047\n",
      "number of tweets parsed:  5000000\n",
      "total time elapsed:  145.757845879\n",
      "number of tweets parsed:  5500000\n",
      "total time elapsed:  162.547792912\n",
      "number of tweets parsed:  6000000\n",
      "total time elapsed:  183.822963953\n",
      "number of tweets parsed:  6500000\n",
      "total time elapsed:  203.087458849\n",
      "number of tweets parsed:  7000000\n",
      "total time elapsed:  227.908416033\n",
      "number of tweets parsed:  7500000\n",
      "total time elapsed:  252.842293024\n",
      "number of tweets parsed:  8000000\n",
      "total time elapsed:  281.925946951\n",
      "number of tweets parsed:  8500000\n",
      "total time elapsed:  310.747802973\n",
      "number of tweets parsed:  9000000\n",
      "total time elapsed:  342.543689966\n",
      "number of tweets parsed:  9500000\n",
      "total time elapsed:  384.558521986\n",
      "number of tweets parsed:  10000000\n",
      "total time elapsed:  436.425371885\n",
      "number of tweets parsed:  10500000\n",
      "total time elapsed:  486.773155928\n",
      "number of tweets parsed: "
     ]
    }
   ],
   "source": [
    "shooting_df = ReadToDf(500000, 'data/cleanedShootingTweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shooting_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indictment_df = ReadToDf(500000, 'data/cleanedIndTweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indictment_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "This is where we're going to clean data that we've read in. The only cleaning that we need to do is that we need to convert the \"created_at\" column to a datetime object. The rest of the cleaning data is done in the script `development_scripts/clean_json_data.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recodeData (dataframe):\n",
    "    # Creating a parseable dataset    \n",
    "    dataframe['createdDatetime'] =  pd.to_datetime(\n",
    "        dataframe['created_at'], \n",
    "        format = '%a %b %d %H:%M:%S +0000 %Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's recode the dates for the shooting data and the indictment data! These opperations are done in place, so we don't actually have to return anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('recoding shooting dataset')\n",
    "recodeData(shooting_df)\n",
    "print('recoding indictment dataset')\n",
    "recodeData(indictment_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Tweets over Time\n",
    "In this section, we mostly want to explore broadly the data we have -- both the shooting and indictment-related tweets. First, we want to understand the volume of tweets that we have, and when there are spikes in the data. We will do this for both the shooting and the indictment tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets after the Mike Brown Shooting\n",
    "In the dataset related to the shooting, we have approximately 11 million tweets worth of data. Over the course of the first week, statements from police, from the family of Michael Brown, statements from the police officer Darren Wilson, and unrest from the streets were recorded and shared wildly across the web. To get a general understanding of the data, we are going to plot the number of tweets over time and annotate this plot with important events that happened over the course of the two weeks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will group the tweets by minute, and then count the number of tweets that happened each minute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Raw numbers of tweets over time\n",
    "shootingTweetsGroupedTime = (shooting_df\n",
    "                                 .set_index('createdDatetime')\n",
    "                                 .groupby([pd.TimeGrouper('Min')])\n",
    "                                 .count()\n",
    "                                 .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "shootingTweetsGroupedTime.plot(kind='line', x='createdDatetime', y='created_at', ax=ax)\n",
    "plt.title('Number of Tweets by Users')\n",
    "\n",
    "ax.set_ylabel('Count of tweets')\n",
    "ax.set_xlabel('Date/Time')\n",
    "\n",
    "#Overlaying Special Events\n",
    "#August 11, 10AM - first police department demonstration\n",
    "#August 11, 4PM - parents ask for stop to violence\n",
    "#August 11, 8PM - tear gas used at protest\n",
    "#August 12, 10AM - protest in St. Louis\n",
    "#August 12, 12PM - Al Sharpton addresses crowds\n",
    "#August 12, 4PM - Obama makes a statement\n",
    "#August 13, 6PM - Reporters detained\n",
    "#August 13, 9PM - Tear gas used again, and at reporters\n",
    "#August 14, 7AM - Antonio French released from jail\n",
    "#August 14, 11:40AM - Obama Address\n",
    "#August 14, 6PM - Silent Vigils, first peaceful night\n",
    "#August 15, 8:45AM - Darren Wilson names\n",
    "#August 15, 12:30PM - Assassination statement by family\n",
    "#August 15 Evening - Huge amounts of protest\n",
    "#August 16, 3PM - State of emergency issued, curfew issued\n",
    "#August 17 - Afternoon - Federal Autopsy Ordered\n",
    "#August 18 - 2AM - Federal Gaurd Ordered into town\n",
    "#August 18 - 3:30PM - third Obama address\n",
    "#August 18 - Trayvon Martin's mother published letter\n",
    "#August 19 - 7AM - family on the Today Show\n",
    "#August 19 - 1PM - another man is shot\n",
    "#August 22 - 12PM - national gaurd ordered to withdraw\n",
    "#August 23 - Online fundraisers for officer surpass that of Brown\n",
    "#August 23 - 7PM - Obama address\n",
    "#August 24 - 12PM - Private Viewing, Requests for no Violence\n",
    "#August 25 - Funeral\n",
    "\n",
    "calendar_dates = {'FirstDemo':datetime(2014,8,11,10,0,0),\n",
    "                 'ParentReq':datetime(2014,8,11,16,0,0),\n",
    "                 'TearGas':datetime(2014,8,11,20,0,0),\n",
    "                 'StLouisProtest':datetime(2014,8,12,10,0,0),\n",
    "                 'AlSharpton':datetime(2014,8,12,12,0,0),\n",
    "                 'Obama':datetime(2014,8,12,16,0,0),\n",
    "                 'Reporters':datetime(2014,8,13,18,0,0),\n",
    "                 'TearGas2':datetime(2014,8,13,21,0,0),\n",
    "                 'AntonioFrench':datetime(2014,8,14,7,0,0),\n",
    "                 'Obama2':datetime(2014,8,14,11,40,0),\n",
    "                 'SilentVigils':datetime(2014,8,14,18,0,0),\n",
    "                 'DarrenWilson':datetime(2014,8,15,8,45,0),\n",
    "                 'CharacterAssassination':datetime(2014,8,15,12,30,0),\n",
    "                 'StateOfEmergency':datetime(2014,8,16,15,0,0),\n",
    "                 'FederalGaurd':datetime(2014,8,18,2,0,0),\n",
    "                 'Obama3':datetime(2014,8,18,15,30,0),\n",
    "                 'TodayShow':datetime(2014,8,19,7,0,0),\n",
    "                 'AnotherShot':datetime(2014,8,19,13,0,0),\n",
    "                 'GaurdWithdrawn':datetime(2014,8,22,12,0,0),\n",
    "                 'Obama4':datetime(2014,8,23,19,0,0),\n",
    "                 'Viewing':datetime(2014,8,24,12,0,0)}\n",
    "\n",
    "for event in calendar_dates:\n",
    "    plt.axvline(x=calendar_dates.get(event),ymin=0, ymax=4000, linewidth=4,color='g',label=event)\n",
    "    plt.text(calendar_dates.get(event),600,event)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, a certain percentage of users have place or geoencoding available on their tweets. Spatially we can see how tweets were generated following the shooting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latLonPopulated = df[(df['x'] != 0) & (df['y'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Note, the animation code courtesy of and adapted from http://jakevdp.github.io/blog/2013/05/12/embedding-matplotlib-animations/\n",
    "VIDEO_TAG = \"\"\"<video controls>\n",
    " <source src=\"data:video/x-m4v;base64,{0}\" type=\"video/mp4\">\n",
    " Your browser does not support the video tag.\n",
    "</video>\"\"\"\n",
    "\n",
    "def anim_to_html(anim):\n",
    "    if not hasattr(anim, '_encoded_video'):\n",
    "        with NamedTemporaryFile(suffix='.mp4') as f:\n",
    "            anim.save(f.name, fps=20, extra_args=['-vcodec', 'libx264', '-pix_fmt', 'yuv420p'])\n",
    "            video = open(f.name, \"rb\").read()\n",
    "        anim._encoded_video = video.encode(\"base64\")\n",
    "    \n",
    "    return VIDEO_TAG.format(anim._encoded_video)\n",
    "\n",
    "def display_animation(anim):\n",
    "    plt.close(anim._fig)\n",
    "    return HTML(anim_to_html(anim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(xlim=(-180, 180), ylim=(-75, 75))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "scat, = plt.plot([], [],'o')\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    scat.set_data([], [])\n",
    "    return scat,\n",
    "\n",
    "# animation function.  This is called sequentially by the animator\n",
    "def animate(i):\n",
    "    day = round(i/24) + 17\n",
    "    hour = i - (day-17)*24\n",
    "    subset = []\n",
    "    subset = latLonPopulated[\n",
    "        (latLonPopulated['createdDatetime_day'] == day) & \n",
    "        (latLonPopulated['createdDatetime_hour'] == hour)]\n",
    "\n",
    "    scat.set_data(subset.x,subset.y)\n",
    "    \n",
    "    return scat,\n",
    "\n",
    "# animation.Animation._repr_html_ = anim_to_html #this yields a depreciation warning, heads up\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, frames=336, interval=5000, blit=True)\n",
    "\n",
    "# call our new function to display the animation\n",
    "display_animation(anim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And over all time, statically, this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the cartopy map, going simple outline for now\n",
    "plt.figure(figsize=(15,15))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "#straight-up coordinate data which we just finished recoding\n",
    "plt.scatter(latLonPopulated.x,latLonPopulated.y,color='r')\n",
    "plt.axis([-180, 180, -75, 75])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#as a hexbin instead\n",
    "#the cartopy map, going simple outline for now\n",
    "plt.figure(figsize=(15,15))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "#straight-up coordinate data which we just finished recoding\n",
    "plt.hexbin(latLonPopulated.x,latLonPopulated.y,cmap=cm.jet) #add bins='log' to see a log based chart\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets after the Decision not to Indict\n",
    "Now, we also want to look over the same analysis for the tweets following the decision not to indict Darren Wilson. First, let's get an idea of the number of tweets that occurred over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Raw numbers of tweets over time\n",
    "indictmentTweetsGroupedTime = (indictment_df\n",
    "                                 .set_index('createdDatetime')\n",
    "                                 .groupby([pd.TimeGrouper('Min')])\n",
    "                                 .count()\n",
    "                                 .reset_index())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "indictmentTweetsGroupedTime.plot(kind='line', x='createdDatetime', y='created_at', ax=ax)\n",
    "plt.title('Number of Tweets by Users')\n",
    "\n",
    "ax.set_ylabel('Count of tweets')\n",
    "ax.set_xlabel('Date/Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, let's also take a look at the geographic distribution of those tweets over time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latLonPopulated = df[(df['x'] != 0) & (df['y'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Note, the animation code courtesy of and adapted from http://jakevdp.github.io/blog/2013/05/12/embedding-matplotlib-animations/\n",
    "VIDEO_TAG = \"\"\"<video controls>\n",
    " <source src=\"data:video/x-m4v;base64,{0}\" type=\"video/mp4\">\n",
    " Your browser does not support the video tag.\n",
    "</video>\"\"\"\n",
    "\n",
    "def anim_to_html(anim):\n",
    "    if not hasattr(anim, '_encoded_video'):\n",
    "        with NamedTemporaryFile(suffix='.mp4') as f:\n",
    "            anim.save(f.name, fps=20, extra_args=['-vcodec', 'libx264', '-pix_fmt', 'yuv420p'])\n",
    "            video = open(f.name, \"rb\").read()\n",
    "        anim._encoded_video = video.encode(\"base64\")\n",
    "    \n",
    "    return VIDEO_TAG.format(anim._encoded_video)\n",
    "\n",
    "def display_animation(anim):\n",
    "    plt.close(anim._fig)\n",
    "    return HTML(anim_to_html(anim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(xlim=(-180, 180), ylim=(-75, 75))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "scat, = plt.plot([], [],'o')\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    scat.set_data([], [])\n",
    "    return scat,\n",
    "\n",
    "# animation function.  This is called sequentially by the animator\n",
    "def animate(i):\n",
    "    day = round(i/24) + 17\n",
    "    hour = i - (day-17)*24\n",
    "    subset = []\n",
    "    subset = latLonPopulated[\n",
    "        (latLonPopulated['createdDatetime_day'] == day) & \n",
    "        (latLonPopulated['createdDatetime_hour'] == hour)]\n",
    "\n",
    "    scat.set_data(subset.x,subset.y)\n",
    "    \n",
    "    return scat,\n",
    "\n",
    "# animation.Animation._repr_html_ = anim_to_html #this yields a depreciation warning, heads up\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, frames=336, interval=5000, blit=True)\n",
    "\n",
    "# call our new function to display the animation\n",
    "display_animation(anim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To just see where the tweets came from over time, we can plot all the geo-located tweets at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the cartopy map, going simple outline for now\n",
    "plt.figure(figsize=(15,15))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "#straight-up coordinate data which we just finished recoding\n",
    "plt.scatter(latLonPopulated.x,latLonPopulated.y,color='r')\n",
    "plt.axis([-180, 180, -75, 75])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#as a hexbin instead\n",
    "#the cartopy map, going simple outline for now\n",
    "plt.figure(figsize=(15,15))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "#straight-up coordinate data which we just finished recoding\n",
    "plt.hexbin(latLonPopulated.x,latLonPopulated.y,cmap=cm.jet) #add bins='log' to see a log based chart\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtags - Sophia\n",
    "Now, let's explore the different hashtags used by users. First, let's create a dataframe that has one row per tweet-hashtag combination. So, a tweet using two hashtags would translate into a dataframe with two rows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create this dataframe by looping over the rows in the dataframe, and looping over the hashtags in each tweet. For each tweet, we will create a json object that represents the row that should be added to our new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtagRows = []\n",
    "hashtagMap = {'MICHAELBROWN': 'MIKEBROWN'}\n",
    "for i,tweet in df.iterrows():\n",
    "    for hashtag in tweet['entities_hashtags_text']:\n",
    "        \n",
    "        mappedhashtag = hashtag.upper()\n",
    "        if (mappedhashtag in hashtagMap):\n",
    "            mappedhashtag = hashtagMap[mappedhashtag]\n",
    "        #Do we want to map michael brown to mike brown and similar stuff?\n",
    "        hashtagRows.append({\n",
    "                'createdDatetime': tweet['createdDatetime'],\n",
    "                'hashtag': mappedhashtag,\n",
    "                'tweetId': tweet['id_str'],\n",
    "                'x': tweet['x'],\n",
    "                'y': tweet['y'],\n",
    "                'createdDatetime_day': tweet['createdDatetime_day'],\n",
    "                'createdDatetime_hour': tweet['createdDatetime_hour']\n",
    "            })\n",
    "print \"creating dataframe\"\n",
    "hashtagsDf = pd.DataFrame(hashtagRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtagsDf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataframe, let's get the most popular tweets! We will do this by grouping the dataframe by hashtag and then aggregating by count. We'll sort by count, and then transform that information to a list that we can use later. Right now, we'll start by getting the top 10 hashtags and plotting those over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numTopHashtags = 10\n",
    "popularHashtagsList = (hashtagsDf\n",
    "                   .groupby('hashtag')\n",
    "                   .count()\n",
    "                   .reset_index()\n",
    "                   .sort_values(by='createdDatetime', ascending=False)['hashtag']\n",
    "                   .tolist())[0:numTopHashtags]\n",
    "\n",
    "print(popularHashtagsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the most popular hashtags, let's filter the hashtags dataframe for just those hashtags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popularHashtagsDf = hashtagsDf[hashtagsDf.hashtag.isin(popularHashtagsList)]\n",
    "popularHashtagsDf.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's count the number of times each hashtag was used in a given minute. To do this, we will group the dataframe by datetime.minute and hashtag and then aggregate by count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtagTimeCounts = (popularHashtagsDf\n",
    "                     .set_index('createdDatetime')\n",
    "                     .groupby([pd.TimeGrouper('H'), 'hashtag'])\n",
    "                     .count()\n",
    "                     .reset_index())\n",
    "hashtagTimeCounts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've gotten the counts for a particular hashtag every minute, let's plot this over time as a line graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for hashtag in popularHashtagsList:\n",
    "    filteredHashtagTimeCounts = hashtagTimeCounts[hashtagTimeCounts.hashtag == hashtag]\n",
    "    filteredHashtagTimeCounts.plot(kind = 'line', x = 'createdDatetime', y = 'tweetId', label = hashtag, ax = ax)\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Number of Tweets over Time')\n",
    "plt.title('Hashtag useage over Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see the number of times each hashtag was used in a tweet in this dataset. Unfortunately, it appears that the hashtag \"Ferguson\" was used much more than any of the other hashtags, so this plot is a little hard to read. To adjust for that, let's \"normalize\" each hashtag line on this graph. To do this, we will divide the number of times that hashtag was used in any given minute by the maxiumum times that hashtag was used in any minute. This will mean that we can see all the lines on the same set of axes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "for hashtag in popularHashtagsList:\n",
    "    filteredHashtagTimeCounts = hashtagTimeCounts[hashtagTimeCounts.hashtag == hashtag]\n",
    "    maxCount = filteredHashtagTimeCounts['tweetId'].max()\n",
    "    filteredHashtagTimeCounts['normalizedCounts'] = filteredHashtagTimeCounts['tweetId']/maxCount\n",
    "    filteredHashtagTimeCounts.plot(kind = 'line', x = 'createdDatetime', y = 'normalizedCounts', label = hashtag, ax = ax)\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Number of Tweets over Time')\n",
    "plt.title('Hashtag useage over Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most popular hashtags seem to follow a similar trajectory. First of all, let's spend a little bit of time talking about what each hashtag means.\n",
    "\n",
    "**Ferguson:**\n",
    "This hashtag appears to be refering in a boader context to the events that occured in Ferguson. [source](http://www.dailydot.com/politics/ferguson-michael-brown-eric-garner-black-lives-matter-hashtag-activism/)\n",
    "\n",
    "**Mike/Michael Brown:**\n",
    "This hashtag, somewhat self-explanatorily, refers to Michael Brown, the unarmed teen that was shot by police. [source](http://www.dailydot.com/politics/ferguson-michael-brown-eric-garner-black-lives-matter-hashtag-activism/)\n",
    "\n",
    "**TCOT:**\n",
    "This hashtag stands for \"Top Conservatives on Twitter\" and is used to bring together conservatives on twitter. The corresponding liberal hashtag is \"P2\". [source](http://blog.sfgate.com/ybenjamin/2010/07/27/the-secret-twitter-war-for-americas-independents-tcot-vs-p2/)  Very quickly, after the events in Ferguson, there started to be political discussions about Ferguson. \n",
    "\n",
    "**Hands Up Don't Shoot:**\n",
    "\"Hands up Don't Shoot\" was a phrase commonly used in the Ferguson protests. This phrase references witness' statements that say that Michael Brown had his hands up before he was shot by police. This phrase was adopted in peaceful protest after the Ferguson shooting [source](http://www.cbc.ca/newsblogs/yourcommunity/2014/08/hands-up-dont-shoot-gesture-spreads-online-in-support-of-ferguson-protesters.html)\n",
    "\n",
    "**STL:**\n",
    "This hashtag, similarly to the hashtag \"Ferguson\" is in reference o the city of Saint Louis, Missouri.  [source](https://tagdef.com/stl)\n",
    "\n",
    "**Unite Blue:**\n",
    "Although this hashtag is typically used to refer to \"uniting liberals on twitter\" [source](), in this context this hashtag refers to people uniting in support of the police force. [source]()\n",
    "\n",
    "**Ezell Ford: **\n",
    "Ezell Ford is another African American man that was also killed after being shot by police. He was shot on August 11th, 2014 in LA. [source](https://en.wikipedia.org/wiki/Shooting_of_Ezell_Ford)\n",
    "\n",
    "**Ferguson Shooting:**\n",
    "This hashtag, appears to be used to just refer to events surrounding the Ferguson shooting. [source]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TALK ABOUT THE GRAPH HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even see where these hashtags are most popular over time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latLonPopulated_HT = hashtagsDf[(hashtagsDf['x'] != 0) & (hashtagsDf['y'] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotAnimationProperly(list_functions, data_to_plot, colors_to_plot):\n",
    "    for i in range(len(list_functions)):\n",
    "        list_functions[i].set_data(data_to_plot[i].x,data_to_plot[i].y)\n",
    "        list_functions[i].set_color(colors_to_plot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(xlim=(-180, 180), ylim=(-75, 75))\n",
    "# plt.axis([-180, 180, -75, 75])\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "scat, = plt.plot([], [],'o')\n",
    "scat_top_1, = plt.plot([], [],'o')\n",
    "scat_top_2, = plt.plot([], [],'o')\n",
    "scat_top_3, = plt.plot([], [],'o')\n",
    "scat_top_4, = plt.plot([], [],'o')\n",
    "scat_top_5, = plt.plot([], [],'o')\n",
    "scat_top_6, = plt.plot([], [],'o')\n",
    "scat_top_7, = plt.plot([], [],'o')\n",
    "scat_top_8, = plt.plot([], [],'o')\n",
    "scat_top_9, = plt.plot([], [],'o')\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "patches = []\n",
    "def animate(i):\n",
    "    day = round(i/24) + 17\n",
    "    hour = i - (day-17)*24\n",
    "    subset = []\n",
    "    color = []\n",
    "    for j,hashtag in enumerate(popularHashtagsList):\n",
    "        subset.append(latLonPopulated_HT[\n",
    "            (latLonPopulated_HT['createdDatetime_day'] == day) & \n",
    "            (latLonPopulated_HT['createdDatetime_hour']== hour) & \n",
    "            (latLonPopulated_HT['hashtag'] == hashtag)])\n",
    "        color.append(cm.jet(j/float(len(popularHashtagsList))))\n",
    "\n",
    "    plotAnimationProperly([scat,scat_top_1,scat_top_2,scat_top_3,scat_top_4,scat_top_5,scat_top_6,scat_top_7,scat_top_8,scat_top_9],subset,color)\n",
    "    \n",
    "    return scat,scat_top_1,scat_top_2,scat_top_3,scat_top_4,scat_top_5,scat_top_6,scat_top_7,scat_top_8,scat_top_9,\n",
    "\n",
    "# animation.Animation._repr_html_ = anim_to_html\n",
    "#set up the legend\n",
    "for j, hashtag in enumerate(popularHashtagsList):\n",
    "    patches.append(mpatches.Patch(color=cm.jet(j/float(len(popularHashtagsList))), label=hashtag))\n",
    "plt.legend(handles=patches, loc='best')\n",
    "\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, frames=48, interval=5000, blit=False)\n",
    "\n",
    "# call our new function to display the animation\n",
    "display_animation(anim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the cartopy map, going simple outline for now\n",
    "plt.figure(figsize=(15,15))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "for j,hashtag in enumerate(popularHashtagsList):\n",
    "    subset = latLonPopulated_HT[(latLonPopulated_HT['hashtag'] == hashtag)]\n",
    "    if len(subset.x) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        plt.scatter(subset.x,subset.y,color=cm.jet(j/float(len(popularHashtagsList))),label=hashtag)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles,labels, loc='best')\n",
    "plt.axis([-180, 180, -75, 75])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#each hashtag, hexbin\n",
    "plt.figure(figsize=(100,20))\n",
    "\n",
    "for j,hashtag in enumerate(popularHashtagsList):\n",
    "    subset = latLonPopulated_HT[(latLonPopulated_HT['hashtag'] == hashtag)]\n",
    "    ax = plt.subplot(2,5,j+1,projection=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    ax.hexbin(subset.x,subset.y,cmap=cm.jet,bins='log')\n",
    "    plt.title(hashtag)\n",
    "    plt.axis([-180, 180, -75, 75])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users\n",
    "introduction goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verified Users - Sophia\n",
    "Additionally, one of the things we wanted to investigate was the role that verified users play in raising awareness about a certain event. On twitter verified users are users that represent an organization (like a news source) or a public figure. We hypotheize that getting more verified users involved in talking about social justice will cause more non-verified users to also be engaged in the conversation, as they see what verififed users are saying. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "verified = df[df.user_verified == True]\n",
    "normal = df[df.user_verified == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the number of tweets by verified users every minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groupedVerified = verified.set_index('createdDatetime').groupby([pd.TimeGrouper('Min')]).count().reset_index()\n",
    "groupedNormal = normal.set_index('createdDatetime').groupby([pd.TimeGrouper('Min')]).count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot this information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "\n",
    "groupedVerified.plot(kind='line', x='createdDatetime', y='created_at', label='Verified Users', ax=ax)\n",
    "groupedNormal.plot(kind='line', x='createdDatetime', y='created_at', ax = ax, secondary_y=True, label='Non-verified Users')\n",
    "plt.title('Number of tweets by Users')\n",
    "\n",
    "ax.set_ylabel('Count of tweets (Verified users)', color='b')\n",
    "ax.right_ax.set_ylabel('Count of tweets (Non-Verified users)', color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see whether or not the number of non-verified users' tweets and number of verified tweets there are are related, let's correlate the number of tweets by verified users and the number of tweets by non-verified users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verifiedtweetsCount = groupedVerified.sort_values(by='createdDatetime')['created_at'].tolist()\n",
    "normaltweetsCount = groupedNormal.sort_values(by='createdDatetime')['created_at'].tolist()\n",
    "\n",
    "corr = np.correlate(verifiedtweetsCount, normaltweetsCount, mode='full')\n",
    "delays = range(-len(corr)/2, len(corr)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(delays,corr)\n",
    "plt.xlabel('delay in number of hours')\n",
    "plt.ylabel('correlation')\n",
    "plt.title('Correlation between number of verified tweets and number of non-verified account tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's also get the index (in hours) for the highest autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delays[np.argmax(corr)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the correlation of those two vectors finds that they are most correlated when the verifiedTweetsCount and the normalTweets count are offset by 402. This means that about 6.7 hours after an increase in ____ there tends to also be an increase in ___."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweets - Victoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retweetRows = []\n",
    "for i,tweet in df.iterrows():\n",
    "    for retweeter in tweet['entities_user_mentions_screen_name']:\n",
    "        mappeduser = retweeter.upper()\n",
    "        retweetRows.append({\n",
    "                'createdDatetime': tweet['createdDatetime'],\n",
    "                'retweeter': mappeduser,\n",
    "                'tweetId': tweet['user_screen_name'].upper(),\n",
    "                'x': tweet['x'],\n",
    "                'y': tweet['y'],\n",
    "                'retweet_count': tweet['retweet_count'],\n",
    "                'user_verified': tweet['user_verified'],\n",
    "                'entities_hashtags_text': tweet['entities_hashtags_text'],\n",
    "#                 'activist': tweet['activist']\n",
    "            })\n",
    "print \"creating dataframe\"\n",
    "retweetDf = pd.DataFrame(retweetRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colormap = {False:'blue',True:'red'}\n",
    "retweetDf['node_color'] = retweetDf['user_verified'].apply(lambda x: colormap.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = {}\n",
    "for i,tweet in retweetDf.iterrows():\n",
    "    pos[tweet['tweetId'].upper()] = np.asarray([tweet['retweet_count'],tweet['createdDatetime']])\n",
    "    pos[tweet['retweeter'].upper()] = np.asarray([tweet['retweet_count'],tweet['createdDatetime']]) #temporary until we have all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "G=nx.from_pandas_dataframe(retweetDf[0:1000:], source='tweetId',target='retweeter')\n",
    "# other_pos = nx.spectral_layout(G)\n",
    "\n",
    "nx.draw_networkx(G,alpha=0.2,cmap=cm.jet,font_size=0, node_size=10, node_color=retweetDf['node_color'])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latLonPopulated_RT = retweetDf[(retweetDf['x'] != 0) & (retweetDf['y'] != 0)]\n",
    "\n",
    "pos = {}\n",
    "for i,tweet in latLonPopulated_RT.iterrows():\n",
    "    pos[tweet['tweetId'].upper()] = np.asarray([tweet['x'],tweet['y']])\n",
    "    pos[tweet['retweeter'].upper()] = np.asarray([tweet['x'],tweet['y']]) #temporary until we have all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "G=nx.from_pandas_dataframe(latLonPopulated_RT, source='tweetId',target='retweeter')\n",
    "# other_pos = nx.spectral_layout(G)\n",
    "\n",
    "nx.draw_networkx(G,pos,alpha=0.1,cmap=cm.jet,font_size=0,node_size=10, node_color=latLonPopulated_RT['node_color'])\n",
    "plt.axis([-130, -50, 20, 50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#and now, to take a look at networks based upon hashtags...\n",
    "numTopHashtags = 160\n",
    "popularHashtagsList = (hashtagsDf\n",
    "                   .groupby('hashtag')\n",
    "                   .count()\n",
    "                   .reset_index()\n",
    "                   .sort_values(by='createdDatetime', ascending=False)['hashtag']\n",
    "                   .tolist())[0:numTopHashtags]\n",
    "\n",
    "print popularHashtagsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtagMap = {\n",
    "#                 'MIKEBROWN':'blue',\n",
    "               'JUSTICEFORMIKEBROWN':'blue',\n",
    "               'TCOT':'red',\n",
    "               'HANDSUPDONTSHOOT':'blue',\n",
    "               'UNITEBLUE':'red',\n",
    "               'DONTSHOOT':'blue',\n",
    "               'CRIMEBUTNOTIME':'blue',\n",
    "               'POLICEBRUTALITY':'blue',\n",
    "#                'RESPECT':'blue',\n",
    "               'P2':'blue',\n",
    "#                'BEFREE':'blue',\n",
    "#                'MIKEBROWNRALLY':'blue',\n",
    "               'DARRENWILSON':'red',\n",
    "               'STANDWITHFERGUSON':'blue',\n",
    "#                'RIPMIKEBROWN':'blue',\n",
    "               'BLACKLIVESMATTER':'blue',\n",
    "#                'OCCUPYFERGUSON':'blue',\n",
    "               'POLICESTATE':'blue',\n",
    "               'WHITEPRIVILEGE':'blue',\n",
    "               'IFTHEYGUNNEDMEDOWN':'blue',\n",
    "               'HANDSUP':'blue',\n",
    "#                'POLICE':'red',\n",
    "               'GOP':'red',\n",
    "#                'NOJUSTICENOPEACE':'blue',\n",
    "               'WEGOTYOUSIS':'blue',\n",
    "#                'SOLIDARITY':'blue',\n",
    "               'RACISM':'blue',\n",
    "               'CIVILRIGHTS':'blue',\n",
    "               'FERGUSONCOVERUP':'blue',\n",
    "               'WARONWHITES':'red',\n",
    "               'MIKEBROWNBHEARD':'blue',\n",
    "               'BLACKTWITTER':'blue',\n",
    "#                'TRAYVONMARTIN':'blue',\n",
    "               'REDNATIONRISING':'red',\n",
    "               'TLOT':'red',\n",
    "               'TGDN':'red',\n",
    "               'PJNET':'red',\n",
    "               '2A':'red',\n",
    "               'NMOS14':'blue',\n",
    "              'FOXNEWS':'red',\n",
    "#               'KNOWYOURRIGHTS':'blue',\n",
    "              'CAPTRONJOHNSON':'red',\n",
    "              'BUNDYRANCH':'red',\n",
    "              'CCOT':'red',\n",
    "              'COPSLIE':'blue',\n",
    "              'LNYHBT':'red',\n",
    "#               'FILMTHEPOLICE':'blue',\n",
    "#               'ALSHARPTON':'blue',\n",
    "              'NOJUSTICENOSLEEP':'blue',\n",
    "              'FTP':'blue',\n",
    "#               'WHEREISDARRENWILSON':'blue',\n",
    "              'NRA':'red',\n",
    "              'ARRESTDARRENWILSON':'blue',\n",
    "                   }\n",
    "\n",
    "retweetHT_Rows = []\n",
    "for i,tweet in retweetDf.iterrows():\n",
    "    for hashtag in tweet['entities_hashtags_text']:\n",
    "        mappedhashtag = hashtag.upper()\n",
    "        if (mappedhashtag in hashtagMap):\n",
    "            mappedhashtag = hashtagMap[mappedhashtag]\n",
    "#         else:\n",
    "#             mappedhashtag = 'green'\n",
    "            retweetHT_Rows.append({\n",
    "                    'createdDatetime': tweet['createdDatetime'],\n",
    "                    'hashtag': mappedhashtag,\n",
    "                    'tweetId': tweet['tweetId'],\n",
    "                    'x': tweet['x'],\n",
    "                    'y': tweet['y'],\n",
    "                    'retweeter': tweet['retweeter'],\n",
    "                    'retweet_count': tweet['retweet_count'],\n",
    "                    'user_verified': tweet['user_verified'],\n",
    "                })\n",
    "print \"creating dataframe\"\n",
    "retweetHashtagsDf = pd.DataFrame(retweetHT_Rows)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "G=nx.from_pandas_dataframe(retweetHashtagsDf[0:5000:], source='tweetId',target='retweeter')\n",
    "\n",
    "nx.draw_spring(G,alpha=1, font_size=0, node_size=50, node_color=retweetHashtagsDf['hashtag'])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtagMapRed = {\n",
    "#                 'MIKEBROWN':'blue',\n",
    "#                'JUSTICEFORMIKEBROWN':'blue',\n",
    "               'TCOT':'red',\n",
    "#                'HANDSUPDONTSHOOT':'blue',\n",
    "               'UNITEBLUE':'red',\n",
    "#                'DONTSHOOT':'blue',\n",
    "#                'CRIMEBUTNOTIME':'blue',\n",
    "#                'POLICEBRUTALITY':'blue',\n",
    "#                'RESPECT':'blue',\n",
    "#                'P2':'blue',\n",
    "#                'BEFREE':'blue',\n",
    "#                'MIKEBROWNRALLY':'blue',\n",
    "               'DARRENWILSON':'red',\n",
    "#                'STANDWITHFERGUSON':'blue',\n",
    "#                'RIPMIKEBROWN':'blue',\n",
    "#                'BLACKLIVESMATTER':'blue',\n",
    "#                'OCCUPYFERGUSON':'blue',\n",
    "#                'POLICESTATE':'blue',\n",
    "#                'WHITEPRIVILEGE':'blue',\n",
    "#                'IFTHEYGUNNEDMEDOWN':'blue',\n",
    "#                'HANDSUP':'blue',\n",
    "#                'POLICE':'red',\n",
    "               'GOP':'red',\n",
    "#                'NOJUSTICENOPEACE':'blue',\n",
    "#                'WEGOTYOUSIS':'blue',\n",
    "#                'SOLIDARITY':'blue',\n",
    "#                'RACISM':'blue',\n",
    "#                'CIVILRIGHTS':'blue',\n",
    "#                'FERGUSONCOVERUP':'blue',\n",
    "               'WARONWHITES':'red',\n",
    "#                'MIKEBROWNBHEARD':'blue',\n",
    "#                'BLACKTWITTER':'blue',\n",
    "#                'TRAYVONMARTIN':'blue',\n",
    "               'REDNATIONRISING':'red',\n",
    "               'TLOT':'red',\n",
    "               'TGDN':'red',\n",
    "               'PJNET':'red',\n",
    "               '2A':'red',\n",
    "#                'NMOS14':'blue',\n",
    "              'FOXNEWS':'red',\n",
    "#               'KNOWYOURRIGHTS':'blue',\n",
    "              'CAPTRONJOHNSON':'red',\n",
    "              'BUNDYRANCH':'red',\n",
    "              'CCOT':'red',\n",
    "#               'COPSLIE':'blue',\n",
    "              'LNYHBT':'red',\n",
    "#               'FILMTHEPOLICE':'blue',\n",
    "#               'ALSHARPTON':'blue',\n",
    "#               'NOJUSTICENOSLEEP':'blue',\n",
    "#               'FTP':'blue',\n",
    "#               'WHEREISDARRENWILSON':'blue',\n",
    "              'NRA':'red',\n",
    "#               'ARRESTDARRENWILSON':'blue',\n",
    "                   }\n",
    "\n",
    "hashtagMapBlue = {\n",
    "                'MIKEBROWN':'blue',\n",
    "               'JUSTICEFORMIKEBROWN':'blue',\n",
    "#                'TCOT':'red',\n",
    "               'HANDSUPDONTSHOOT':'blue',\n",
    "#                'UNITEBLUE':'red',\n",
    "               'DONTSHOOT':'blue',\n",
    "               'CRIMEBUTNOTIME':'blue',\n",
    "               'POLICEBRUTALITY':'blue',\n",
    "               'RESPECT':'blue',\n",
    "               'P2':'blue',\n",
    "               'BEFREE':'blue',\n",
    "               'MIKEBROWNRALLY':'blue',\n",
    "#                'DARRENWILSON':'red',\n",
    "               'STANDWITHFERGUSON':'blue',\n",
    "               'RIPMIKEBROWN':'blue',\n",
    "               'BLACKLIVESMATTER':'blue',\n",
    "               'OCCUPYFERGUSON':'blue',\n",
    "               'POLICESTATE':'blue',\n",
    "               'WHITEPRIVILEGE':'blue',\n",
    "               'IFTHEYGUNNEDMEDOWN':'blue',\n",
    "               'HANDSUP':'blue',\n",
    "#                'POLICE':'red',\n",
    "#                'GOP':'red',\n",
    "               'NOJUSTICENOPEACE':'blue',\n",
    "               'WEGOTYOUSIS':'blue',\n",
    "               'SOLIDARITY':'blue',\n",
    "               'RACISM':'blue',\n",
    "               'CIVILRIGHTS':'blue',\n",
    "               'FERGUSONCOVERUP':'blue',\n",
    "#                'WARONWHITES':'red',\n",
    "               'MIKEBROWNBHEARD':'blue',\n",
    "               'BLACKTWITTER':'blue',\n",
    "               'TRAYVONMARTIN':'blue',\n",
    "#                'REDNATIONRISING':'red',\n",
    "#                'TLOT':'red',\n",
    "#                'TGDN':'red',\n",
    "#                'PJNET':'red',\n",
    "#                '2A':'red',\n",
    "               'NMOS14':'blue',\n",
    "#               'FOXNEWS':'red',\n",
    "              'KNOWYOURRIGHTS':'blue',\n",
    "#               'CAPTRONJOHNSON':'red',\n",
    "#               'BUNDYRANCH':'red',\n",
    "#               'CCOT':'red',\n",
    "              'COPSLIE':'blue',\n",
    "#               'LNYHBT':'red',\n",
    "              'FILMTHEPOLICE':'blue',\n",
    "              'ALSHARPTON':'blue',\n",
    "              'NOJUSTICENOSLEEP':'blue',\n",
    "              'FTP':'blue',\n",
    "              'WHEREISDARRENWILSON':'blue',\n",
    "#               'NRA':'red',\n",
    "              'ARRESTDARRENWILSON':'blue',\n",
    "                   }\n",
    "\n",
    "retweetHT_Rows = []\n",
    "for i,tweet in retweetDf.iterrows():\n",
    "    for hashtag in tweet['entities_hashtags_text']:\n",
    "        mappedhashtag = hashtag.upper()\n",
    "        if (mappedhashtag in hashtagMapRed):\n",
    "            mappedhashtag = hashtagMapRed[mappedhashtag]\n",
    "            retweetHT_Rows.append({\n",
    "                    'createdDatetime': tweet['createdDatetime'],\n",
    "                    'hashtag': mappedhashtag,\n",
    "                    'tweetId': tweet['tweetId'],\n",
    "                    'x': tweet['x'],\n",
    "                    'y': tweet['y'],\n",
    "                    'retweeter': tweet['retweeter'],\n",
    "                    'retweet_count': tweet['retweet_count'],\n",
    "                    'user_verified': tweet['user_verified'],\n",
    "                })\n",
    "            break\n",
    "        elif (mappedhashtag in hashtagMapBlue):\n",
    "            mappedhashtag = hashtagMapBlue[mappedhashtag]\n",
    "            retweetHT_Rows.append({\n",
    "                    'createdDatetime': tweet['createdDatetime'],\n",
    "                    'hashtag': mappedhashtag,\n",
    "                    'tweetId': tweet['tweetId'],\n",
    "                    'x': tweet['x'],\n",
    "                    'y': tweet['y'],\n",
    "                    'retweeter': tweet['retweeter'],\n",
    "                    'retweet_count': tweet['retweet_count'],\n",
    "                    'user_verified': tweet['user_verified'],\n",
    "                })\n",
    "            break\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "            \n",
    "print \"creating dataframe\"\n",
    "retweetHashtagsDf = pd.DataFrame(retweetHT_Rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "G=nx.from_pandas_dataframe(retweetHashtagsDf[0:1000:], source='tweetId',target='retweeter')\n",
    "\n",
    "nx.draw_networkx(G,alpha=1, font_size=0, node_size=50, node_color=retweetHashtagsDf['hashtag'])\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latLonPopulated_RTHT = retweetHashtagsDf[(retweetHashtagsDf['x'] != 0) & (retweetHashtagsDf['y'] != 0)]\n",
    "\n",
    "pos = {}\n",
    "for i,tweet in latLonPopulated_RTHT.iterrows():\n",
    "    pos[tweet['tweetId'].upper()] = np.asarray([tweet['x'],tweet['y']])\n",
    "    pos[tweet['retweeter'].upper()] = np.asarray([tweet['x'],tweet['y']]) #temporary until we have all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "\n",
    "G=nx.from_pandas_dataframe(latLonPopulated_RTHT, source='tweetId',target='retweeter')\n",
    "# other_pos = nx.spectral_layout(G)\n",
    "\n",
    "nx.draw_networkx(G,pos,alpha=0.2,font_size=0,node_size=40, node_color=latLonPopulated_RTHT['hashtag'])\n",
    "plt.axis([-130, -50, 20, 50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions - Victoria and Sophia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
